---
title: "P8131_BM2_sj2921_hw1"
author: "Shan Jiang"
date: "2/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
library(caret)
```
## Problem 3 

#### Import data frame 
```{r}
df = data.frame(id = rep(1:10), 
           results = c(0, 1, 0, 0, 1, 0, 0, 0, 1, 0), 
             Total = 10) 
typeof(df)

```

### Maximum likelihood estimation

#### (1) $H_0: \pi = 0.1$
we are interested in testing 
$$H_0:\pi = 0.1,  H_1:\pi \neq 0.1$$

In this dataset Y = 3, n = 10, so $\hat p = \frac{3}{10}$
Then, we calculate the wald-test statistic 

##### Wald Test
```{r}
sqrt(0.3 * 0.7 / 10)
wald_1 = 0.2/0.1449138
```
\[
\begin{eqnarray}
TS_w & = & \frac{(\frac{3}{10} - 0.1)}{\sqrt{\frac{3}{10} (1 - \frac{3}{10})/ 10}}
     & = & \frac{0.2}{\sqrt{0.3 \cdot 0.7 /10}}
     & = & \frac{0.2}{0.1449}
     & \approx & 1.38
\end{eqnarray}
\]
```{r}
wald_1 
```

##### Rao’s Score Test (a.k.a. Lagrange Multiplier Test)
```{r}
sqrt(0.1 * (1 - 0.1) / 10)
Rao_1 = 0.2/0.0948

```
\[
\begin{eqnarray}
TS_r & = & \frac{(\frac{3}{10} - 0.1)}{\sqrt{0.1 (1 - 0.1)/ 10}}
     & = & \frac{0.1}{\sqrt{0.1 \cdot 0.9 /10}}
     & = & \frac{0.2}{0.0948}
     & \approx & -1.265
\end{eqnarray}
\]
```{r}
Rao_1
```

##### likelihood Ratio Test
```{r}
3 * log(0.3/0.1) + 7 * log(0.7/0.9)
LR_1 = 1.5366*2
LR_1
```
Recall from previous example, Y = 3, n = 10, so $\hat p = \frac{3}{10}$.
Then, the Likelihood Ratio Statistic is
$$2[3\cdot log(\frac{0.3}{0.1}) + 7\cdot log{(\frac{0.7}{0.9})}] \approx 3.0732 $$

#### (2) $H_0: \pi = 0.3$
we are interested in testing 
$$H_0:\pi = 0.3,  H_1:\pi \neq 0.3$$

In this dataset Y = 3, n = 10, so $\hat p = \frac{3}{10}$
Then, we calculate the wald-test statistic 

##### Wald Test
\[
\begin{eqnarray}
TS_w & = & \frac{(\frac{3}{10} - 0.3)}{\sqrt{\frac{3}{10} (1 - \frac{3}{10})/ 10}}
     & = & \frac{0}{\sqrt{0.3 \cdot 0.7 /10}}
     & = & \frac{0}{0.1449}
     & = & 0
\end{eqnarray}
\]

##### Rao’s Score Test (a.k.a. Lagrange Multiplier Test)
\[
\begin{eqnarray}
TS_r & = & \frac{(\frac{3}{10} - 0.3)}{\sqrt{0.3 (1 - 0.3)/ 10}}
     & = & \frac{0}{\sqrt{0.3 \cdot 0.7 /10}}
     & = & \frac{0}{0.0948}
     & = & 0
\end{eqnarray}
\]

##### likelihood Ratio Test
The Likelihood Ratio Statistic is

$$2[3 \cdot log(\frac{0.3}{0.3}) + 7\cdot log{(\frac{0.7}{0.7})}] = 0$$
All the three statistics are equal to 0.

#### (3) $H_0: \pi = 0.5$
we are interested in testing 
$$H_0:\pi = 0.5,  H_1:\pi \neq 0.5$$

In this dataset Y = 3, n = 10, so $\hat p = \frac{3}{10}$
Then, we calculate the wald-test statistic 

##### Wald Test
```{r}
sqrt(0.3 * 0.7 / 10)
wald_3 = -0.2/0.1449138
```
\[
\begin{eqnarray}
TS_w & = & \frac{(\frac{3}{10} - 0.5)}{\sqrt{\frac{3}{10} (1 - \frac{3}{10})/ 10}}
     & = & \frac{-0.2}{\sqrt{0.3 \cdot 0.7 /10}}
     & = & \frac{-0.2}{0.1449}
     & \approx & -1.380
\end{eqnarray}
\]
```{r}
wald_3
```

##### Rao’s Score Test (a.k.a. Lagrange Multiplier Test)
```{r}
sqrt(0.5 * (1 - 0.5) / 10)
Rao_3 = -0.2/sqrt(0.5 * (1 - 0.5) / 10)
```
\[
\begin{eqnarray}
TS_r & = & \frac{(\frac{3}{10} - 0.5)}{\sqrt{0.5 (1 - 0.5)/ 10}}
     & = & \frac{- 0.2}{\sqrt{0.5 \cdot 0.5 /10}}
     & = & \frac{- 0.2}{0.0948}
     & \approx & 2.11
\end{eqnarray}
\]
```{r}
Rao_3
```

##### likelihood Ratio Test
```{r}
3 * log(0.3/0.5) + 7 * log(0.7/0.5)
LR_3 = 3 * log(0.3/0.5) + 7 * log(0.7/0.5) * 2
```
Recall from previous example, Y = 3, n = 10, so $\hat p = \frac{3}{10}$.
Then, the Likelihood Ratio Statistic is
$$2[3\cdot log(\frac{0.3}{0.5}) + 7\cdot log{(\frac{0.7}{0.5})}] \approx 3.1781 $$
```{r}
LR_3
```

The absolute value of Wald test statistic is larger than score test, that is $|TS_w|$ > $|TS_s|$, meaning score test is more conservative and maintained a higher acuracy.  

The Likelihood Ratio Statistic is between $TS_r^2$ and $TS_w^2$, the Likelihood Ratio Statistic is asymptotically under the null within large samples.

### 3.Comment on the conclusions 
```{r}
## grouped boxplot
results = data.frame(pi = c(0.1, 0.3, 0.5),
           y_obs = 0.3,
           test1 = c(wald_1,Rao_1, LR_1),
           test2 = 0,
           test3 = c(wald_3,Rao_3, LR_3))

re_df = gather(results, key = "test_id", value = "statistic", -pi)

ggplot(re_df, aes(x = pi, y = statistic ))  + 
    geom_point( ) +
    facet_grid(~test_id)
  

```

Here, we have drawn conclusions from the graph above. 
* Under the null, these three $\sim \chi_1^2$
* Since $|TS_w|$ > $|TS_s|$
